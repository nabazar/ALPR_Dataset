{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhh21xEO74QX87+Dz1N48f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabazar/ALPR_Dataset/blob/main/PathPlanningRLv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "qmAW_qg1goeT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image as im\n",
        "from gym import spaces\n",
        "from numpy.matlib import repmat\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.epsilon = 0.7\n",
        "        self.alpha=0.5\n",
        "        self.gamma=0.85\n",
        "\n",
        "        self.Q_table=np.random.rand(env.num_states, 8)\n",
        "        # for i in range(0,env.num_states):\n",
        "        #   for j in range(0,8):\n",
        "        #     self.Q_table[i,j]=float(np.random.rand(1))\n",
        "\n",
        "\n",
        "    def updat_Q_value(self,st,nxtst,action,reward):\n",
        "\n",
        "      self.Q_table[st][action]=self.Q_table[st][action]+self.alpha*(reward+self.gamma*np.max(self.Q_table[nxtst])-self.Q_table[st][action])\n",
        "      # return self.Q_table\n",
        "\n",
        "    def get_action(self,st):\n",
        "        if np.random.random() < self.epsilon:\n",
        "            # exploit\n",
        "\n",
        "            ex=np.exp(self.Q_table[st])\n",
        "            py=ex/sum(ex)\n",
        "\n",
        "            return np.argmax(py)\n",
        "        else:\n",
        "            # explore\n",
        "            return np.random.randint(8)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSZKnrEoAzY-"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pickle import TUPLE1\n",
        "class PathPlanningEnv():\n",
        "  def __init__(self,A):\n",
        "    self.A=A\n",
        "    self.xmax=600\n",
        "    self.xmin=0\n",
        "    self.ymax=600\n",
        "    self.ymin=0\n",
        "    self.nx=A.shape[0]\n",
        "    self.ny=A.shape[1]\n",
        "    dx=(self.xmax-self.xmin)/(2*self.nx)\n",
        "    dy=(self.ymax-self.ymin)/(2*self.ny)\n",
        "    self.D=np.sqrt(dx**2+dy**2)\n",
        "    # self.num_states = env.nx*env.ny*3\n",
        "    self.num_states = self.nx*self.ny\n",
        "    states=[]\n",
        "    # kk=-1\n",
        "    act=[(1,0),(1,1),(0,1),(-1,1),(-1,0),(-1,-1),(0,-1),(-1,1)]\n",
        "    actions=[]\n",
        "    for i in range(0,self.nx):\n",
        "      for j in range(0,self.ny):\n",
        "        # for k in range(0,3):\n",
        "          # kk=kk+1\n",
        "        states.append(tuple([i,j]))\n",
        "\n",
        "          # states.append(tuple([i,j,k]))\n",
        "        a=[]\n",
        "        for ii in range(0,8):\n",
        "          if act[ii][0]+i<self.nx and act[ii][1]+j<self.ny :\n",
        "            a.append(ii)\n",
        "\n",
        "        actions.append(tuple(a))\n",
        "    self.states=states\n",
        "    self.actions=actions\n",
        "\n",
        "    self.action_space = spaces.Discrete(8)\n",
        "    self.observation_space = spaces.Dict({\n",
        "            \"xr\": spaces.Box(low = 0, high = self.nx, shape=(self.nx,), dtype=int),\n",
        "            \"yr\": spaces.Box(low = 0, high = self.ny, shape=(self.ny,), dtype=int)})\n",
        "    # self.observation_space = spaces.Dict({\n",
        "    #         \"xr\": spaces.Box(low = 0, high = self.nx, shape=(self.nx,), dtype=int),\n",
        "    #         \"yr\": spaces.Box(low = 0, high = self.ny, shape=(self.ny,), dtype=int),\n",
        "    #         \"obs_situ\": spaces.Box(low = 0, high = 3, shape=(3,), dtype=int)})\n",
        "\n",
        "  def reset(self):\n",
        "    self.xr = np.random.randint(self.nx)\n",
        "    self.yr = np.random.randint(self.ny)\n",
        "    # self.obs_situ =np.random.randint(3)\n",
        "    while self.A.iloc[self.xr,self.yr]==0:\n",
        "      self.xr = np.random.randint(self.nx)\n",
        "      self.yr = np.random.randint(self.ny)\n",
        "    state=self.get_observation()\n",
        "\n",
        "    return state\n",
        "  def get_observation(self):\n",
        "\n",
        "    observation=(int(self.xr),int(self.yr))\n",
        "    # observation=(int(self.xr),int(self.yr),int(self.obs_situ))\n",
        "\n",
        "    return observation\n",
        "\n",
        "  def step(self,action):\n",
        "    next_state=self.get_observation()\n",
        "    if action==0:\n",
        "      self.xr=self.xr+1\n",
        "      self.yr=self.yr+1\n",
        "    elif action==1:\n",
        "      self.xr=self.xr+1\n",
        "      self.yr=self.yr+1\n",
        "    elif action==2:\n",
        "      self.xr=self.xr+1\n",
        "      self.yr=self.yr+1\n",
        "    elif action==3:\n",
        "      self.xr=self.xr-1\n",
        "      self.yr=self.yr+1\n",
        "    elif action==4:\n",
        "      self.xr=self.xr-1\n",
        "      self.yr=self.yr+0\n",
        "    elif action==5:\n",
        "      self.xr=self.xr-1\n",
        "      self.yr=self.yr-1\n",
        "    elif action==6:\n",
        "      self.xr=self.xr+0\n",
        "      self.yr=self.yr-1\n",
        "    elif action==7:\n",
        "      self.xr=self.xr+1\n",
        "      self.yr=self.yr-1\n",
        "    flag=0\n",
        "    done=0\n",
        "\n",
        "    if self.xr>=self.nx or self.yr>=self.ny:\n",
        "      flag=1\n",
        "      reward=-25\n",
        "    else:\n",
        "      if self.xr==self.goal[0] and self.yr==self.goal[1]:\n",
        "          reward=25\n",
        "          flag=1\n",
        "          done=1\n",
        "      elif self.A.iloc[self.xr,self.yr]==255:\n",
        "          reward=-10\n",
        "      else:\n",
        "          reward=-1\n",
        "\n",
        "      next_state=self.get_observation()\n",
        "\n",
        "    return next_state,reward,done,flag\n",
        "  def state2index(self,state):\n",
        "    if (state[0],state[1]) in self.states:\n",
        "      state_index = self.states.index((state[0],state[1]))\n",
        "\n",
        "    else:\n",
        "      state_index=[]\n",
        "\n",
        "    return state_index\n",
        "\n",
        "\n",
        "\n",
        "  def render(self):\n",
        "\n",
        "    fig=plt.figure(figsize=(3,3))\n",
        "    clear_output(wait=True)\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(env.start[1],env.start[0],'-or')\n",
        "    plt.plot(env.goal[1],env.goal[0],'-og')\n",
        "    xp=[]\n",
        "    yp=[]\n",
        "    for i in range(0, len(env.Path)):\n",
        "      xp.append(env.Path[i][0])\n",
        "      yp.append(env.Path[i][1])\n",
        "    plt.plot(yp,xp,'-b')\n",
        "    plt.plot(yp[0],xp[0],'-om')\n",
        "    plt.plot(yp[-1],xp[-1],'-oc')\n",
        "    plt.xlim([0,env.ny])\n",
        "    plt.ylim([0,env.nx])\n",
        "    plt.imshow(env.A)\n",
        "    plt.show()\n",
        "\n",
        "    plt.subplot(2, 1,2)\n",
        "    plt.plot(self.rewards,'-b')\n",
        "    clrs = ['red' if (x < 0) else 'green' for x in self.ep_reward]\n",
        "    x=np.linspace(0,len(self.ep_reward),len(self.ep_reward))\n",
        "    plt.bar(x, self.ep_reward, color=clrs)\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Rewards')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tHf6Wxvoidm7"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = pd.read_csv('/content/Map20x20.csv')"
      ],
      "metadata": {
        "id": "rZ9ai3J1WyzW"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env=PathPlanningEnv(A)"
      ],
      "metadata": {
        "id": "PS5bJ0CpjcH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14bd0d78-13d2-480d-90d8-7281ca539498"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent=Agent(env)"
      ],
      "metadata": {
        "id": "IpvMUH5g6yeP"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_episode=200000\n",
        "episode=0\n",
        "env.goal= [int(3),int(4)]\n",
        "env.A.iloc[env.goal[0],env.goal[1]]=100\n",
        "env.ep_reward=[]\n",
        "env.rewards=[]\n",
        "while episode<=max_episode:\n",
        "  # A0=env.A\n",
        "  state=env.reset()\n",
        "  env.state=state\n",
        "  flag=0\n",
        "  max_stp=50\n",
        "  stp=0\n",
        "\n",
        "  step_reward=[]\n",
        "  env.start=[state[0],state[1]]\n",
        "\n",
        "  Path=[]\n",
        "  while flag==0 and stp<=max_stp:\n",
        "    env.xr=int(state[0])\n",
        "    env.yr=int(state[1])\n",
        "    Path.append((env.xr,env.yr))\n",
        "\n",
        "    # env.obs_situ=state[2]\n",
        "    env.state=state\n",
        "    st=env.state2index(state)\n",
        "    action=agent.get_action(st)\n",
        "    if action in env.actions[st] :\n",
        "\n",
        "      next_state,reward,done,flag=env.step(action)\n",
        "    else:\n",
        "      next_state,reward,done,flag=state,-25,0,1\n",
        "    nxtst=env.state2index(next_state)\n",
        "    if nxtst !=[]:\n",
        "      agent.updat_Q_value(st,nxtst,action,reward)\n",
        "    else:\n",
        "     flag=1\n",
        "    state=next_state\n",
        "    Path.append((env.xr,env.yr))\n",
        "    env.Path=Path\n",
        "\n",
        "\n",
        "    stp=stp+1\n",
        "    step_reward.append(reward)\n",
        "  env.ep_reward.append(np.mean(step_reward))\n",
        "  env.rewards.append(np.mean(env.ep_reward))\n",
        "  if episode%1000==0:\n",
        "    env.render()\n",
        "\n",
        "  episode=episode+1\n",
        "\n"
      ],
      "metadata": {
        "id": "378hQOh7Jbkq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "27a41faf-efc4-43aa-8306-4b48f9a257c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJwAAACVCAYAAACtt5OFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANNElEQVR4nO3df0yTdx4H8PdTpBUqPLUilApVXJzovOgFRUFdWI6FucTpptnIXRY1i07W7oIsWY7dlNPtrm6XqLeN6R+LcN7Ow23xx8XduS3gz4kaWLgcIJxOJ2xQfpzXFqq00H7vD+SZleLa0n5b2s8racLz8O3zfMrzzvM83+d5yldgjDEQwoks1AWQ6EKBI1xR4AhXFDjCFQWOcEWBI1xR4AhXFDjC1aRQF/Agl8uFjo4OJCQkQBCEUJdDPGCMoa+vD1qtFjKZb/ussAtcR0cH0tPTQ10G8UJ7ezvS0tJ8eo9PgTMajTh69ChaWloQFxeH3NxcvPPOO5g7d67UZmBgAK+99hqqqqpgt9tRUFCADz/8ECkpKV6tIyEhAcDwh0lMTPSlPOKn3u3/xI0PHLC71NI8hew2ZhvkSHpr1aj2VqsV6enp0rbyheDLvdSnnnoKhYWFWLJkCYaGhvDGG2+gsbERzc3NUCqVAICioiJ8/vnnqKyshCiKMBgMkMlk+Prrr71ah9VqhSiKyMMaTBJiff5A5Kd90dEg/dy7ax6a92+7N3X/KYwLgID5RXuRtOOqNFemuSZtI4vF4vNOwafAPainpwfJyck4e/YsHn/8cVgsFkyfPh2HDx/G+vXrAQAtLS2YN28eamtrsWzZsp9cJgUu+EYCxxzA5Yzfw+GaDvewjXBBIetF9s3fQpAPzxlv4MbVS7VYLAAAtXp4V1xfX4/BwUHk5+dLbTIzM6HT6VBbW+txGXa7HVar1e1F+LBUzoTDlQzPYQMAGeyuZFgqZwZsnX4HzuVyobi4GMuXL8eCBQsAACaTCXK5HCqVyq1tSkoKTCaTx+UYjUaIoii9qMPAj+M77/ZO3rbzht+B0+v1aGxsRFVV1bgKKC0thcVikV7t7e3jWh7xnnyWd0cTb9t5w6/AGQwGnDx5EqdPn3brFms0GjgcDpjNZrf2XV1d0Gg0HpelUCiQmJjo9iJ8iBtvYUjoh2vMFi4oZN0QN94K2Dp9ChxjDAaDAceOHUNNTQ0yMjLcfp+VlYXY2FhUV1dL81pbW9HW1oacnJzAVEwC5q9/fwZvsWwIABge7DsO91IfefljqcMQCD5dh9Pr9Th8+DBOnDiBhIQE6bxMFEXExcVBFEW89NJLKCkpgVqtRmJiIl599VXk5OR41UMl/Hz82TPY+Os/gkGGC/PP4hctuNdbHaaQ9eKRlz92uyQSCD4Fbv/+/QCAvLw8t/kVFRXYuHEjAGDv3r2QyWRYt26d24VfEj6ksDEZtrz4N5TuLoMwxIZ7rd8lQj7LCnHjLbhiBZyxPYpOpwqpMWasjL827pvv47oOFwx0HS64OtlKNAsGKWzlu8sgk42OwNG+n2NbVyG+H/rx7kPapNv409yVyFco/L4OF3b3Ur1x/5Vy8nAF2kXSz51sJZpgALwI2/M/FI06q/thSIX1TU04pNP5XQ89nhQlpLDh4WFzMgHbugrvhc39gjC7F5ff3Ljhdx0UuCjQw7KksM3AlyjfXYYTp/Lxy6K9uHbD/S7C+Ttz7h1GPd99YAB+sNv9rmVCHlKJbzrwBAAZNDiHTHyEw0dXS52G85cWo/qzF/HoI98BADqdqqDWQnu4KMAQAwCYiiaYsEIKW2JCHzpMGvxi/V/wn29nAQBSY8xBrYUCF0W6kIMmDPdQZ+BLLOzbBiXa0GHSYNGKI1iRugp/mKvEpG4Hxrr9IACYoVD4XQMFLorcxiKMnMdl4iMoBAuysBNKtMEONerxO9xyrsHQB4uGk+V6oFNxb3r37Nl+10CBizIjYROE4fDIBasUOgfUuI5fAeeToS4bhKLX5vZeRW8/PnvsMTyTlOT3+qnTEAUUuA1gdNhGyAUrsthO1KMMNuiG253/CLgI/O9nqXBMU0L+Xxum/rsTzw2tHtczixS4KPAo/gwtapCIbzHWF+HkghXZrBT9SP+xnQtQ/6sjoLVEdODuv8r+MJF85+LHz3ZFmjfW3yVGcEDEt0Gth87hCFcUOMIVBY5wRYEjXEVMp8HbDkKoeKrP287KeN7riaf38vr70R6OcEWBI1xR4AhXFDjCVcR0GjwJ5ckx8Yz2cIQrChzhigJHuKLAEa4ocIQrChzhigJHuKLAEa4ocISriL7TEO53FcK9vmCgPRzhigJHuKLAEa4ocISriO40hJNI/rK1L2gPR7iiwBGuKHCEK58Dd+7cOaxevRparRaCIOD48eNuv2eMYceOHUhNTUVcXBzy8/Nx7dq1QNVLJjifA2ez2bBw4UKUl5d7/P27776L9957DwcOHMDly5ehVCpRUFCAgYGBcRfrqy86Gka9SGj53EtdtWoVVq0aPQ46MLx327dvH958802sWbMGAHDo0CGkpKTg+PHjKCwsHF+1ZMIL6DnczZs3YTKZ3EaEFkURS5cupRGhCYAAB25kdMGUlBS3+TQiNBkR8l4qjQgdXQIauJFRn7u6utzm04jQZERAA5eRkQGNRuM2IrTVasXly5dpRGgCwI9ean9/P65fvy5N37x5Ew0NDVCr1dDpdCguLsbbb7+NOXPmICMjA9u3b4dWq8XatWsDWTeZoHwOXF1dHZ544glpuqSkBACwYcMGVFZW4vXXX4fNZsOWLVtgNpuxYsUKnDp1CpMnTw5c1WTC8jlweXl5eNgg0oIgYNeuXdi1a9e4CiORKeS9VBJdKHCEKwoc4YoCR7iiwBGuIvo7DdH2ReOJ8HlpD0e4osARrihwhCsKHOEqojsNntD3GkKL9nCEKwoc4YoCR7iiwBGuIqbTQJ0Bz8JtgDvawxGuKHCEKwoc4YoCR7iiwBGuKHCEKwoc4SpirsN54nQxnDfdRecdJ1LjY7BSE4cYmRDqsqJaxAbu6I1+bLvYg+9tTmlemjIGe3On47nZU0JYWXSLyMAdvdGP578ygTEA9+3Qvu934vmvTPjkSU3UhM7buwq87tRE3Dmc08Ww7WIPGOAWNtw3XXKxF07X2P+uggRPxAXuvOmu22H0QQxAu20I5013+RVFJBEXuM47Y4fNn3YksCIucKnxMQFtRwIr4gK3UhOHNGXMqNO3EQKAdOUkrNTE8SyL3BNxgYuRCdibOx3AmH0G7MlNoutxIRJxgQOA52ZPwSdPajBD6X7YTFNOiqpLIuEoIq/DAcOhWzNLSXcawkzEBg4YPrzmaeNDXQa5z4QM3ET4L0ETjbd/069c41tPRJ7DkfBFgSNcUeAIV0ELXHl5OWbNmoXJkydj6dKluHLlSrBWRSaQoATuyJEjKCkpQVlZGb755hssXLgQBQUF6O7uDsbqyAQSlMDt2bMHmzdvxqZNmzB//nwcOHAA8fHxOHjwYDBWRyaQgF8WcTgcqK+vR2lpqTRPJpMhPz/f46jQdrsddrtdmrZYLACAIQwOP0tEwsr9o3Y/bAissQQ8cL29vXA6nR5HhW5paRnV3mg0YufOnaPmX8A/Al0aCQBRFKWf+/r63Ka9EfILv6WlpdKIhABgNpsxc+ZMtLW1+fxhSOBZrVakp6ejvb1dGjyZMYa+vj5otVqflxfwwCUlJSEmJsbrUaEVCgUUCsWo+aIo0ujQYeTB0br93RkEvNMgl8uRlZXlNiq0y+VCdXU1jQpNgnNILSkpwYYNG7B48WJkZ2dj3759sNls2LRpUzBWRyaQoATuhRdeQE9PD3bs2AGTyYRFixbh1KlTozoSnigUCpSVlXk8zBL+Ar09BOZP35YQP9G9VMIVBY5wRYEjXFHgCFdhFzh6rCk0jEYjlixZgoSEBCQnJ2Pt2rVobW11azMwMAC9Xo9p06ZhypQpWLdu3agL/D+JhZGqqioml8vZwYMHWVNTE9u8eTNTqVSsq6sr1KVFvIKCAlZRUcEaGxtZQ0MDe/rpp5lOp2P9/f1Sm61bt7L09HRWXV3N6urq2LJly1hubq5P6wmrwGVnZzO9Xi9NO51OptVqmdFoDGFV0am7u5sBYGfPnmWMMWY2m1lsbCz79NNPpTZXr15lAFhtba3Xyw2bQ+rIY035+fnSvIc91kSCa+QxMbVaDQCor6/H4OCg2/bJzMyETqfzafuETeAe9liTyWQKUVXRyeVyobi4GMuXL8eCBQsAACaTCXK5HCqVyq2tr9sn5I8nkfCj1+vR2NiICxcuBHzZYbOH8/WxJhIcBoMBJ0+exOnTp5GWlibN12g0cDgcMJvNbu193T5hEzh6rCm0GGMwGAw4duwYampqkJGR4fb7rKwsxMbGum2f1tZWtLW1+bZ9At27GY+qqiqmUChYZWUla25uZlu2bGEqlYqZTKZQlxbxioqKmCiK7MyZM6yzs1N63blzR2qzdetWptPpWE1NDaurq2M5OTksJyfHp/WEVeAYY+z9999nOp2OyeVylp2dzS5duhTqkqIChr+yNOpVUVEhtbl79y575ZVX2NSpU1l8fDx79tlnWWdnp0/roceTCFdhcw5HogMFjnBFgSNcUeAIVxQ4whUFjnBFgSNcUeAIVxQ4whUFjnBFgSNcUeAIV/8HhldboK7Z8dsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}